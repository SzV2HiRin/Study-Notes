RocketMQ是阿里的一个消息中间件，拥有10W的QPS
使用场景：①：削峰填谷：高并发场景下（秒杀），可以将请求先添加到MQ中，让业务系统在自己的并发能力内消费MQ中的消息，保证系统不会因为高并发而宕机
	 ②：数据分发：当需要调用多个服务时，让多个服务监听同一topic下的tag，发送一条消息，让多个服务并行处理
	 ③：解耦：降低程序间的耦合度（如：发布商品后，要调用微服务来完成静态化页面生成。。。如果现在又要多添加一个功能，不使用mq的话还要在发布商品代码中进行调用，使用mq后让其监听队列即可）
	 ④：异步：提高程序的响应速度，当系统链路调用很长，这时响应速度就会慢，对于一些不重要的业务可以生成一条消息到消息队列中，异步的进行消费
	 ⑤：最终一致性：可以通过MQ来实现事务的最终一致性
	 ⑥：补偿机制：可以通过mq对一些数据进行补偿
优点：降低了程序间的耦合，可以削锋，异步调用提高程序的性能，数据分发
缺点：系统复杂性变高，可能会出现消息丢失的问题
RocketMQ的构成：NameServer和broker两部分组成，broker向NameServer上报状态，NameServer选定broker进行消息的存储或消息的读取。一个Broker中包含4个队列。
RocketMQ中的关键字：Group:组名，Topic：topic名，Tag：tag名
Producer：有三种发送消息的方式：同步（必须等待消息消费方回应后才能继续发送消息），异步（无需等待消费方回应可直接发送下一条消息），单向（只负责发送消息）
Consumer：集群环境下有两种接收方式：负载均衡和广播，针对同一消息，负载均衡是集群中某一结点接收，广播则是集群中所有结点都进行接收（默认是负载均衡）
	   有两种消费模式：pull：主动从消息服务器中拉取消息进行消费  push：监听某一topic有消息过来自动进行消费
RocketMQ的用法：
一：普通用法
二：顺序消息（确保消息的顺序性），eg：可以设置一个标识，让一些消息存入同一队列中（默认情况下，消息会被负载均衡的存储到4个队列中），消费这些消息时也按顺序消费。
				（处理学生信息时，通过学生所在班级的ID作为标识，这样就可以让一个班级中的学生存入一个队列中顺序消费了）
三：延时消息，可以设置，将消息发送给broker后，经过指定时间后，消息接收方才能接收到消息（查看订单是否支付超时，订单创建后，发送消息，1小时后接收到查看是否支付超时，超时的话就关闭订单）
	 RabbitMQ则需要通过过期消息+死信队列来实现，发送方将消息发送到Queue1指定过期时间5分钟，没有人监听Queue1队列那么过会儿该消息就进入死信队列，建立死信队列Queue2,接收方监听
	 Queue2，就可以接受到所谓的延时消息了。
	    
四：批量消息：发送方可一次发送多条消息到Broker，将多条消息添加到集合后，发送集合
五：事务消息：在消息发送之前先执行本地事务，若本地事务提交，则将消息成功发送Broker；若本地事务回滚，则取消该消息的发送（用它也可以实现分布式事务）
	        若本地事务没有给出提交或回滚，那么RocketMQ将执行回查方法，查看本地事务的状态，再决定消息是发送还是取消。
六：消息过滤：接收方对于消息的过滤有两种方式，Tag过滤和Sql过滤
	       Tag过滤：接收方在指定要接收的组名,Topic名后可以指定Tag，多个Tag之间用||分割，若表示Topic下的所有Tag，则可以使用*来表示
	       Sql过滤：消息发送方在发送消息时指定一些参数，消息接收方可以根据这些参数设置条件，来接收满足条件的消息

RocketMQ对于消息重复消费问题：在消息接收方集群环境下，默认情况下采用的是负载均衡策略，集群下的多台机器每次只有一台接收到消息（避免了重复消费），也可以设置为广播模式，每台机器都接收同一消息。

RocketMQ的持久化：一般而言消息中间件的持久化方式有两种，一种是存入数据库，一种是存入文件系统，RocketMQ是存入文件系统，当接收到消息后，会将消息存入文件系统当中（1GB）来完成持久化的
								（存储是由ConsumeQueue和CommitLog配合完成）
		存储时采用‘顺序写’的技术保证了效率，在从Broker读取消息时，采用了‘零拷贝’技术保证了读取效率，它会先到ConsumerQueue中获取消息在CommitLog文件中的索引位置，再去
		CommitLog文件中读取消息，避免了消息在用户态到内核态的数据拷贝。

RocketMQ的消息重试：对于顺序消息而言，消息在消费时失败后，RocketMQ会自动的进行消息的重试。（保证应用能即时处理消息消费失败的情况，否则会出现阻塞情况）
		     对于其他消息而言（普通，事务，延时），要自己配置消息消费失败进行重试（在消息接收方的Listener中添加 return action.Reconsumerlater），可在4小时46分内进行16次重试
		     当重试次数达到指定的阈值后，会将该消息加入到死信队列当中（死信队列中的消息不会被消费者消费，且在3天后会被自动删除）
		   
RocketMQ的集群配置：NameServer的配置比较简单，它无需与消息相关联因此，启动多个NameServer实例就可达到集群模式（broker会定时上报消息状态），Broker的配置，一般情况下都是配置多个组，每个
		     组内需要配置一主一从的两个Broker，MasterBroker负责存储消息（写），SlaveBroker负责提供消息（读）

如何保证消息不丢失：三个层面来考虑：一：消息发送方丢失 二：消息队列丢失消息 三：消息接收方丢失
一：解决消息发送方丢失：ACK确认机制（针对于消息发送方，发送消息后，会写入消息队列一个id，消息队列会回传一个ack消息，标明消息接收成功
							  如果消息队列没能处理这个消息，则回调 nack 接口。说明需要重试发送消息）		   
二：解决消息队列丢失消息：消息持久化（针对于MQ,接收到消息后，将消息进行持久化），rocketmq提供了一种同步刷盘机制，只有消息持久化成功后，才会返回给生产者发送成功的标识
三：解决消息消费方丢失消息：常见消息丢失是因为消费方宕机导致，我们可以设置手动提交ACK，消息消费成功后再ACK，对于宕机的消息由于没有ACK提交，消息还会重复执行）
		              如果消费成功手动ack的时候机器挂了，那么等系统恢复该消息还会重复执行，因此需要保证接口的幂等性

RocketMQ如何解决消息堆积问题：当消息的生产速度远远快于消息的消费速度时，会产生大量的消息堆积。
			     解决方法：检查消费方的性能瓶颈，对消费方做优化的处理
			     当已有消息堆积时，可以再临时启动多个队列，快速的消费这些堆积消息，以保证主业务的正常执行

RabbitMQ的集群模式：镜像集群模式，每次在写消息到queue时，都会自动把消息写到多个实例的queue中进行同步，这样一个queue挂了不会丢失消息
配置模式：在RabbitMQ的管理控制台，新增一个镜像集群模式的策略，创建queue时应用该策略，就可以保证每次写消息进来都会写到各个实例的queue中完成同步。

使用到消息队列，不免会产生消息重复消费的问题，所以需要保证消息接收方的幂等性：
解决方法：①：消息发送方生成一个全局ID，消息接收方判断redis中是否存在该ID，如果存在不执行操作，如果不存在则执行操作，然后将该ID存放到redis当中
	 ②：插入数据库的场景：先判断一下数据库中该id是否存在，如果存在则就进行更新即可
	③：微信支付成功回调场景：判断一下支付状态如果是已支付则不执行操作，如果是支付中，则执行操作再将状态改为支付成功
	④：增加日志的操作，先判断数据库日志表是否存在该记录，如果存在则直接返回，如果不存在则执行业务最后添加记录到日志表当中

自己如何设计一个MQ消息队列：①：考虑mq的可用性
			 ②：考虑消息的持久化
			 ③：考虑mq的可扩展性

RocketMQDemo：
用户下单：校验参数，生成预订单，远程调用：扣减库存，扣减用户余额，扣减优惠券，将订单设为可见状态(扣减库存和余额后都需要向数据库插入日志记录，以便以发生异常补偿时可以判断之前是否扣减过，只有
之前扣减过才需要做补偿)
（如果发生异常，则用mq做补偿）
mq补偿的逻辑：try，catch远程调用的代码，在catch中发送mq消息指定topic，其他三个微服务都监听这同一个topic
优惠券微服务：对于该微服务来说，监听消息的接口无需实现幂等性，因为将优惠券设为可用本来就是幂等性操作
库存微服务：首先需要判断扣减日志中之前是否扣减过库存，如果扣减过才有资格补偿，接着判断日志库是否存在之前补偿的记录，补偿过就无需补偿了（保证幂等性），没有补偿过则做补偿并且将此次补偿记录存
放到数据库当中
余额微服务：首先判断余额日志中之前是否扣减过余额，接着判断补偿日志是否补偿过，如果没有的话就对余额做补偿，然后将补偿记录存放到补偿日志中

*基于mq做分布式事务的核心
①：设置日志数据库，正常业务执行完将记录（订单id，用户id之类作为主键标识）存入数据库
②：发生错误，需要做回滚时，通过mq发送消息，其他服务监听到消息，判断成功日志库中是否有业务执行成功的记录（因为有可能有的业务还没来得及执行，就发生了异常，那么这种情况是不需要补偿回滚的）
③：如果之前业务执行成功，那么再判断补偿日志是否存在记录（保证幂等性），没有的话就做补偿，最后将补偿记录存放到业务对应的补偿数据库当中。
一个业务对应2个日志库，一个业务执行成功的库，一个补偿记录的库